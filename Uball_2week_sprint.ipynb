{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "sia3n835q7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Installing required dependencies...\n",
      "==================================================\n",
      "üì¶ Installing google-generativeai: Google AI SDK for Gemini models\n",
      "Requirement already satisfied: google-generativeai in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.179.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "‚úÖ google-generativeai installed successfully\n",
      "üì¶ Installing ffmpeg-python: Python wrapper for FFmpeg video processing\n",
      "Requirement already satisfied: ffmpeg-python in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from ffmpeg-python) (1.0.0)\n",
      "‚úÖ ffmpeg-python installed successfully\n",
      "üì¶ Installing pillow: Image processing for overlay generation\n",
      "Requirement already satisfied: pillow in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (11.3.0)\n",
      "‚úÖ pillow installed successfully\n",
      "üì¶ Installing numpy: Numerical operations for video processing\n",
      "Requirement already satisfied: numpy in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (2.3.2)\n",
      "‚úÖ numpy installed successfully\n",
      "\n",
      "üéâ All dependencies installation complete!\n",
      "\n",
      "üìã Required system dependencies:\n",
      "   - FFmpeg (install via: brew install ffmpeg on macOS, apt install ffmpeg on Ubuntu)\n",
      "   - Make sure FFmpeg is available in your system PATH\n"
     ]
    }
   ],
   "source": [
    "# Required dependencies for basketball video analysis and overlay generation\n",
    "DEPENDENCIES = {\n",
    "    \"google-generativeai\": \"Google AI SDK for Gemini models\",\n",
    "    \"ffmpeg-python\": \"Python wrapper for FFmpeg video processing\", \n",
    "    \"pillow\": \"Image processing for overlay generation\",\n",
    "    \"numpy\": \"Numerical operations for video processing\"\n",
    "}\n",
    "\n",
    "print(\"üîß Installing required dependencies...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package_name, description):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        print(f\"üì¶ Installing {package_name}: {description}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"‚úÖ {package_name} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to install {package_name}: {e}\")\n",
    "\n",
    "# Install all dependencies\n",
    "for package, description in DEPENDENCIES.items():\n",
    "    install_package(package, description)\n",
    "\n",
    "print(\"\\nüéâ All dependencies installation complete!\")\n",
    "print(\"\\nüìã Required system dependencies:\")\n",
    "print(\"   - FFmpeg (install via: brew install ffmpeg on macOS, apt install ffmpeg on Ubuntu)\")\n",
    "print(\"   - Make sure FFmpeg is available in your system PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conwbmmb6qf",
   "metadata": {},
   "source": [
    "# üèÄ Basketball Video Analysis using Gemini 2.5 Pro\n",
    "\n",
    "This notebook analyzes basketball game videos to automatically detect and track key events including:\n",
    "- **2-Point Shots** (Made/Miss)\n",
    "- **3-Point Shots** (Made/Miss) \n",
    "- **Assists**\n",
    "- **Steals**\n",
    "- **Blocks**\n",
    "\n",
    "## üìã Analysis Workflow\n",
    "\n",
    "1. **Setup**: Install dependencies and configure Google AI API\n",
    "2. **Upload**: Upload video file to Google AI platform\n",
    "3. **Process**: Wait for video processing to complete\n",
    "4. **Analyze**: Send video to Gemini 2.5 Pro for basketball event detection\n",
    "5. **Results**: Extract and display structured JSON timeline of events\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Install Dependencies\n",
    "\n",
    "First, we'll install the Google AI Python SDK for accessing Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4b274666-7e8e-429f-b7c9-3b3c975118bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Please enter your Google API key:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "API Key:  AIzaSyBAsS7OV2daJAhf0YxcBtZBwGGPpid_iuc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for video analysis\n",
    "import google.generativeai as genai  # Google AI SDK for Gemini models\n",
    "import time                          # For handling processing delays\n",
    "import json                          # For JSON parsing and formatting\n",
    "import os                            # For environment variable access\n",
    "\n",
    "# Configure API authentication for Google AI services\n",
    "# For Jupyter notebook, we support both environment variables and manual input\n",
    "try:\n",
    "    # First, try to get API key from environment variable\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    \n",
    "    # If not found, prompt user to enter it manually\n",
    "    if not GOOGLE_API_KEY:\n",
    "        print(\"üîë Please enter your Google API key:\")\n",
    "        GOOGLE_API_KEY = input(\"API Key: \")\n",
    "    \n",
    "    # Configure the Google AI SDK with the API key\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    print(\"‚úÖ API Key configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"üö® Could not configure Google API Key.\")\n",
    "    print(\"Please set the GOOGLE_API_KEY environment variable or enter it manually.\")\n",
    "    print(\"You can get your API key from: https://aistudio.google.com/app/apikey\")\n",
    "\n",
    "# --- VIDEO FILE CONFIGURATION ---\n",
    "# IMPORTANT: Update this path to match your actual video file name\n",
    "VIDEO_FILE_PATH = \"sample180s_video-2.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75anu4vd3nb",
   "metadata": {},
   "source": [
    "## Step 2: Configure API Access\n",
    "\n",
    "Set up authentication for Google AI services. You can either:\n",
    "- Set the `GOOGLE_API_KEY` environment variable, or  \n",
    "- Enter your API key manually when prompted\n",
    "\n",
    "Get your API key from: https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ae65b99f-4853-4157-92dd-880ac9297421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file: sample180s_video-2.mp4...\n",
      "Completed upload: files/ukizdo8dcv3n\n",
      "‚è≥ Waiting for video processing...\n",
      "‚è≥ Waiting for video processing...\n",
      "‚è≥ Waiting for video processing...\n",
      "‚è≥ Waiting for video processing...\n",
      "‚úÖ Video processed successfully: https://generativelanguage.googleapis.com/v1beta/files/ukizdo8dcv3n\n"
     ]
    }
   ],
   "source": [
    "# Validate prerequisites before proceeding with video upload\n",
    "if 'GOOGLE_API_KEY' not in locals() or not GOOGLE_API_KEY:\n",
    "    print(\"üö® Please run the previous cell to configure your API key first!\")\n",
    "else:\n",
    "    print(f\"Uploading file: {VIDEO_FILE_PATH}...\")\n",
    "    \n",
    "    # Check if the video file exists in the current directory\n",
    "    if not os.path.exists(VIDEO_FILE_PATH):\n",
    "        print(f\"üö® Error: Video file '{VIDEO_FILE_PATH}' not found!\")\n",
    "        print(\"Please make sure the video file is in the same directory as this notebook.\")\n",
    "    else:\n",
    "        try:\n",
    "            # Upload the video file to Google AI platform\n",
    "            video_file = genai.upload_file(path=VIDEO_FILE_PATH)\n",
    "            print(f\"Completed upload: {video_file.name}\")\n",
    "\n",
    "            # Wait for video processing to complete\n",
    "            # Video files need to be processed before they can be analyzed\n",
    "            while video_file.state.name == \"PROCESSING\":\n",
    "                print(\"‚è≥ Waiting for video processing...\")\n",
    "                time.sleep(10)  # Check every 10 seconds\n",
    "                video_file = genai.get_file(video_file.name)  # Refresh file status\n",
    "\n",
    "            # Check if processing failed\n",
    "            if video_file.state.name == \"FAILED\":\n",
    "                raise ValueError(\"Video processing failed.\")\n",
    "\n",
    "            print(f\"‚úÖ Video processed successfully: {video_file.uri}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üö® Error uploading or processing video: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fio7sh93q0j",
   "metadata": {},
   "source": [
    "## Step 3: Upload Video for Analysis\n",
    "\n",
    "Upload your basketball video to Google AI platform for processing. \n",
    "\n",
    "**Important**: Make sure your video file is in the same directory as this notebook and update the `VIDEO_FILE_PATH` variable with the correct filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd29c55d-8648-4a09-a485-cd1f3efc87e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Sending request to Gemini 2.5 Pro... This may take a moment.\n",
      "‚úÖ Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Validate that video upload was successful before proceeding with analysis\n",
    "if 'video_file' not in locals():\n",
    "    print(\"üö® Please run the previous cell to upload and process your video first!\")\n",
    "else:\n",
    "    try:\n",
    "        # Initialize Gemini 2.5 Pro model for advanced video analysis\n",
    "        model = genai.GenerativeModel(model_name=\"models/gemini-2.5-pro\")\n",
    "\n",
    "        # Comprehensive prompt for detailed basketball analysis with specific JSON structure\n",
    "        prompt = \"\"\"\n",
    "        You are an expert basketball analyst AI specializing in comprehensive game event detection and statistics.\n",
    "        \n",
    "        Analyze the provided basketball video and create a detailed analysis report with the following events:\n",
    "        - 2-Point Shots (made/miss)\n",
    "        - 3-Point Shots (made/miss)\n",
    "        - Assists\n",
    "        - Steals  \n",
    "        - Blocks\n",
    "        - Rebounds (if visible)\n",
    "\n",
    "        IMPORTANT: Return ONLY a valid JSON object with no additional text or markdown formatting.\n",
    "\n",
    "        Required JSON Structure:\n",
    "        {\n",
    "          \"video_info\": {\n",
    "            \"duration\": <video_duration_seconds>,\n",
    "            \"filename\": \"sample180s_video-1.mp4\"\n",
    "          },\n",
    "          \"processing_summary\": {\n",
    "            \"total_events_detected\": <total_count>,\n",
    "            \"processing_timestamp\": \"<current_timestamp>\",\n",
    "            \"event_types_found\": [<list_of_event_types_found>]\n",
    "          },\n",
    "          \"game_statistics\": {\n",
    "            \"total_2pt_attempts\": <count>,\n",
    "            \"total_2pt_made\": <count>,\n",
    "            \"total_3pt_attempts\": <count>, \n",
    "            \"total_3pt_made\": <count>,\n",
    "            \"total_assists\": <count>,\n",
    "            \"total_steals\": <count>,\n",
    "            \"total_blocks\": <count>\n",
    "          },\n",
    "          \"shooting_analysis\": {\n",
    "            \"2pt_shooting\": {\n",
    "              \"percentage\": <percentage>,\n",
    "              \"made\": <count>,\n",
    "              \"attempts\": <count>\n",
    "            },\n",
    "            \"3pt_shooting\": {\n",
    "              \"percentage\": <percentage>,\n",
    "              \"made\": <count>,\n",
    "              \"attempts\": <count>\n",
    "            },\n",
    "            \"overall_fg_percentage\": <percentage>\n",
    "          },\n",
    "          \"defensive_stats\": {\n",
    "            \"steals\": <count>,\n",
    "            \"blocks\": <count>,\n",
    "            \"total_defensive_actions\": <count>\n",
    "          },\n",
    "          \"playmaking\": {\n",
    "            \"assists\": <count>\n",
    "          },\n",
    "          \"detailed_events\": [\n",
    "            {\n",
    "              \"event_type\": \"2pt_shot\" | \"3pt_shot\" | \"assist\" | \"steal\" | \"block\" | \"rebound\",\n",
    "              \"timestamp\": <time_in_seconds>,\n",
    "              \"description\": \"<detailed_description>\",\n",
    "              \"outcome\": \"made\" | \"miss\" | null,\n",
    "              \"location\": \"<court_location>\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "\n",
    "        Critical Requirements:\n",
    "        1. outcome: Use \"made\" or \"miss\" for 2pt_shot and 3pt_shot events, null for all other events\n",
    "        2. Do NOT include: duration, confidence, segment_id fields in detailed_events\n",
    "        3. timestamp should be in seconds (float)\n",
    "        4. Calculate accurate percentages and statistics\n",
    "        5. Include detailed descriptions of each event\n",
    "        6. Identify court locations where events occurred\n",
    "\n",
    "        Return only the JSON object.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"\\nü§ñ Sending request to Gemini 2.5 Pro... This may take a moment.\")\n",
    "\n",
    "        # Send video and prompt to Gemini for analysis\n",
    "        response = model.generate_content([prompt, video_file],\n",
    "                                          request_options={\"timeout\": 600})\n",
    "\n",
    "        print(f\"‚úÖ Analysis complete!\")\n",
    "        \n",
    "        # Store response for the next cell to process\n",
    "        analysis_response = response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üö® Error during analysis: {str(e)}\")\n",
    "        \n",
    "        # Provide specific guidance based on error type\n",
    "        if \"403\" in str(e) or \"permission\" in str(e).lower():\n",
    "            print(\"üí° This error usually means:\")\n",
    "            print(\"   - The file upload session expired\")\n",
    "            print(\"   - The file was deleted too early\")\n",
    "            print(\"   - There's an API quota or permission issue\")\n",
    "            print(\"\\nüîÑ Solution: Re-run the upload cell, then immediately run this analysis cell\")\n",
    "        elif \"quota\" in str(e).lower() or \"rate\" in str(e).lower():\n",
    "            print(\"üí° This looks like a quota/rate limiting error\")\n",
    "            print(\"   - Wait a few minutes before trying again\")\n",
    "            print(\"   - Check your API usage limits\")\n",
    "        else:\n",
    "            print(\"üí° Try:\")\n",
    "            print(\"   1. Re-run the upload cell\")\n",
    "            print(\"   2. Immediately run this cell\")\n",
    "            print(\"   3. Check your API key permissions\")\n",
    "\n",
    "# Note: File cleanup is handled in the final results cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m56b5j3umga",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Video with Gemini 2.5 Pro\n",
    "\n",
    "Send the uploaded video to Gemini 2.5 Pro for basketball event analysis. The AI will identify key events and return a structured JSON response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7dc6ac-d4bf-4293-9cfb-f7c2dd88fe09",
   "metadata": {},
   "outputs": [],
   "source": "# Enhanced Step 5: Generate Real-Time Timeline Overlay Video with JSON Event Data\nif 'analysis_response' not in locals() and 'response' not in locals():\n    print(\"üö® Please run the previous cell to get the analysis response first!\")\nelse:\n    import re\n    import subprocess\n    from datetime import datetime\n    import ffmpeg\n    \n    # Use the most recent response variable available\n    current_response = analysis_response if 'analysis_response' in locals() else response\n    \n    try:\n        # Extract JSON from the AI response\n        response_text = current_response.text\n        json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n        \n        if json_match:\n            json_content = json_match.group(1).strip()\n        else:\n            json_start = response_text.find('{')\n            json_end = response_text.rfind('}') + 1\n            if json_start != -1 and json_end > json_start:\n                json_content = response_text[json_start:json_end]\n            else:\n                json_content = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n                first_brace = json_content.find('{')\n                if first_brace > 0:\n                    json_content = json_content[first_brace:]\n        \n        data = json.loads(json_content)\n        \n        print(\"=\" * 60)\n        print(\"üèÄ ENHANCED BASKETBALL VIDEO OVERLAY GENERATION\")\n        print(\"=\" * 60)\n        \n        # --- REMOVE REBOUNDS FROM JSON ---\n        # Clean event_types_found\n        if 'processing_summary' in data and 'event_types_found' in data['processing_summary']:\n            event_types = data['processing_summary']['event_types_found']\n            if 'rebound' in event_types:\n                event_types.remove('rebound')\n                print(\"‚úÖ Removed 'rebound' from event_types_found\")\n        \n        # Filter out rebound events from detailed_events\n        if 'detailed_events' in data:\n            original_count = len(data['detailed_events'])\n            data['detailed_events'] = [\n                event for event in data['detailed_events'] \n                if event.get('event_type') != 'rebound'\n            ]\n            new_count = len(data['detailed_events'])\n            if original_count != new_count:\n                print(f\"‚úÖ Filtered out {original_count - new_count} rebound events\")\n        \n        # --- SAVE CLEANED JSON TO RESULTS FOLDER ---\n        try:\n            results_dir = \"results\"\n            os.makedirs(results_dir, exist_ok=True)\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            \n            # FIX: Use actual video filename from VIDEO_FILE_PATH\n            video_name_clean = VIDEO_FILE_PATH.replace('.mp4', '').replace('.', '_')\n            json_filename = f\"basketball_analysis_{video_name_clean}_{timestamp}.json\"\n            json_filepath = os.path.join(results_dir, json_filename)\n            \n            # Update video_info in JSON to match actual file\n            data['video_info']['filename'] = VIDEO_FILE_PATH\n            \n            with open(json_filepath, 'w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n            \n            print(f\"üíæ Cleaned analysis JSON saved: {json_filepath}\")\n            print(f\"   File size: {os.path.getsize(json_filepath)} bytes\")\n            \n        except Exception as save_error:\n            print(f\"‚ö†Ô∏è  Could not save JSON file: {save_error}\")\n            json_filepath = None\n        \n        # --- ENHANCED REAL-TIME OVERLAY GENERATION ---\n        if 'detailed_events' in data and data['detailed_events']:\n            # Filter out rebounds again to be sure\n            events = [event for event in data['detailed_events'] if event.get('event_type') != 'rebound']\n            events = sorted(events, key=lambda x: float(x.get('timestamp', 0)))\n            \n            print(f\"\\\\nüìä Processing {len(events)} events (rebounds removed) for enhanced timeline overlay...\")\n            \n            def clean_text_for_ffmpeg(text):\n                \\\"\\\"\\\"Clean text for FFmpeg drawtext filter\\\"\\\"\\\"\n                text = text.replace(\"'\", \"`\")\n                text = text.replace(\":\", \"\\\\\\\\:\")\n                text = text.replace(\"%\", \"%%\")\n                text = text.replace(\"\\\\n\", \" \")\n                text = text.replace(\"[\", \"(\")\n                text = text.replace(\"]\", \")\")\n                return text\n            \n            try:\n                # Get video info using ffmpeg-python\n                probe = ffmpeg.probe(VIDEO_FILE_PATH)\n                duration = float(probe['format']['duration'])\n                video_stream_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n                original_fps = eval(video_stream_info['r_frame_rate'])\n                \n                # Check for audio\n                audio_streams = [stream for stream in probe['streams'] if stream['codec_type'] == 'audio']\n                has_audio = len(audio_streams) > 0\n                \n                print(f\"üìπ Video info: {duration:.1f}s @ {original_fps:.1f}fps, Audio: {has_audio}\")\n                \n                # Initialize video stream\n                input_stream = ffmpeg.input(VIDEO_FILE_PATH)\n                video_stream = input_stream.video\n                audio_stream = input_stream.audio if has_audio else None\n                \n                # --- 1. ADD EVENT CAPTIONS (MIDDLE-BOTTOM) ---\n                for event in events:\n                    description = event.get('description', '')\n                    if not description:\n                        continue\n                        \n                    timestamp = float(event.get('timestamp', 0))\n                    event_type = event.get('event_type', '').upper()\n                    outcome = event.get('outcome', '')\n                    \n                    # Format caption\n                    if outcome:\n                        caption = f\"{event_type} ({outcome.upper()}): {description}\"\n                    else:\n                        caption = f\"{event_type}: {description}\"\n                    \n                    # Clean and limit length\n                    caption = clean_text_for_ffmpeg(caption)\n                    if len(caption) > 100:\n                        caption = caption[:97] + \"...\"\n                    \n                    # Show for 4 seconds\n                    start_time = timestamp\n                    end_time = timestamp + 4.0\n                    \n                    # Apply caption (middle-bottom)\n                    video_stream = video_stream.filter(\n                        'drawtext',\n                        text=caption,\n                        x='(w-text_w)/2',  # Center horizontally\n                        y='h-th-60',       # 60 pixels from bottom\n                        fontsize=22,\n                        fontcolor='white',\n                        box=1,\n                        boxcolor='black@0.8',\n                        boxborderw=5,\n                        enable=f'between(t,{start_time},{end_time})'\n                    )\n                \n                # --- 2. ADD REAL-TIME STATS COUNTER (TOP-LEFT VERTICAL) ---\n                stats = {\"2pt\": 0, \"3pt\": 0, \"assists\": 0, \"blocks\": 0, \"steals\": 0}\n                \n                def apply_stats_block(stream, stats_dict, start, end):\n                    \\\"\\\"\\\"Apply vertical stats block for time window\\\"\\\"\\\"\n                    stats_lines = [\n                        f\"2pt: {stats_dict['2pt']}\",\n                        f\"3pt: {stats_dict['3pt']}\",\n                        f\"assists: {stats_dict['assists']}\",\n                        f\"blocks: {stats_dict['blocks']}\",\n                        f\"steals: {stats_dict['steals']}\"\n                    ]\n                    \n                    base_y = 20\n                    line_height = 35\n                    \n                    for i, line in enumerate(stats_lines):\n                        y_pos = base_y + (i * line_height)\n                        \n                        stream = stream.filter(\n                            'drawtext',\n                            text=line,\n                            x=20,  # 20 pixels from left\n                            y=y_pos,\n                            fontsize=24,\n                            fontcolor='yellow',\n                            box=1,\n                            boxcolor='black@0.8',\n                            boxborderw=5,\n                            enable=f'between(t,{start},{end})'\n                        )\n                    return stream\n                \n                # Apply initial stats (all zeros)\n                first_event_time = events[0].get('timestamp', duration) if events else duration\n                video_stream = apply_stats_block(video_stream, stats, 0, first_event_time)\n                \n                # Update stats at each event (excluding rebounds)\n                for i, event in enumerate(events):\n                    # Update counters based on event type and outcome\n                    event_type = event.get('event_type', '')\n                    outcome = event.get('outcome', '')\n                    \n                    if event_type == '2pt_shot' and outcome == 'made':\n                        stats[\"2pt\"] += 1\n                    elif event_type == '3pt_shot' and outcome == 'made':\n                        stats[\"3pt\"] += 1\n                    elif event_type == 'assist':\n                        stats[\"assists\"] += 1\n                    elif event_type == 'block':\n                        stats[\"blocks\"] += 1\n                    elif event_type == 'steal':\n                        stats[\"steals\"] += 1\n                    \n                    # Apply updated stats for time window\n                    start_time = float(event.get('timestamp', 0))\n                    end_time = events[i + 1].get('timestamp', duration) if i + 1 < len(events) else duration\n                    \n                    video_stream = apply_stats_block(video_stream, stats, start_time, end_time)\n                \n                # --- 3. CREATE OUTPUT VIDEO ---\n                output_video = VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')\n                \n                print(f\"\\\\nüé¨ Generating enhanced timeline overlay video...\")\n                print(f\"   üéØ Top-left: Real-time vertical stats counter\")\n                print(f\"   üì∫ Middle-bottom: Dense event captions\")\n                print(f\"   üö´ Rebounds excluded from tracking\")\n                \n                if has_audio:\n                    output = ffmpeg.output(\n                        video_stream, audio_stream, output_video,\n                        vcodec='libx264', \n                        acodec='copy', \n                        preset='fast', \n                        crf=18,\n                        r=original_fps\n                    )\n                else:\n                    output = ffmpeg.output(\n                        video_stream, output_video,\n                        vcodec='libx264', \n                        preset='fast', \n                        crf=18,\n                        r=original_fps\n                    )\n                \n                # Run FFmpeg\n                ffmpeg.run(output, overwrite_output=True, quiet=False)\n                \n                print(f\"‚úÖ Enhanced timeline overlay video created!\")\n                if os.path.exists(output_video):\n                    file_size = os.path.getsize(output_video)\n                    print(f\"   üìÅ File: {output_video}\")\n                    print(f\"   üìä Size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)\")\n                    \n                    # Final stats\n                    final_stats = stats\n                    print(f\"\\\\nüìà Final Game Stats (No Rebounds):\")\n                    print(f\"   üèÄ 2PT Made: {final_stats['2pt']}\")\n                    print(f\"   üéØ 3PT Made: {final_stats['3pt']}\")\n                    print(f\"   ü§ù Assists: {final_stats['assists']}\")\n                    print(f\"   üõ°Ô∏è  Blocks: {final_stats['blocks']}\")\n                    print(f\"   üí´ Steals: {final_stats['steals']}\")\n                \n            except ffmpeg.Error as e:\n                print(f\"‚ùå FFmpeg error: {e}\")\n                print(\"üí° Debug info:\")\n                print(f\"   stderr: {e.stderr.decode('utf-8') if e.stderr else 'No stderr'}\")\n                print(\"üí° Fallback: Copying original video...\")\n                import shutil\n                output_video = VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')\n                shutil.copy2(VIDEO_FILE_PATH, output_video)\n                print(f\"‚úÖ Original video copied as: {output_video}\")\n                \n            except Exception as video_error:\n                print(f\"üö® Video processing error: {video_error}\")\n                print(\"üí° Fallback: Copying original video...\")\n                import shutil\n                output_video = VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')\n                shutil.copy2(VIDEO_FILE_PATH, output_video)\n                print(f\"‚úÖ Original video copied as: {output_video}\")\n                \n        else:\n            print(\"‚ö†Ô∏è  No events found in JSON data\")\n            \n        # --- DISPLAY TIMELINE PREVIEW (NO REBOUNDS) ---\n        print(\"\\\\n\" + \"=\" * 60)\n        print(\"üìà REAL-TIME TIMELINE PREVIEW (NO REBOUNDS)\")\n        print(\"=\" * 60)\n        \n        if 'detailed_events' in data and data['detailed_events']:\n            # Filter out rebounds for display\n            display_events = [event for event in data['detailed_events'] if event.get('event_type') != 'rebound']\n            print(f\"üìã Timeline overlay progression ({len(display_events)} events, rebounds excluded):\")\n            \n            pt2 = pt3 = ast = blk = stl = 0\n            for i, event in enumerate(display_events[:10], 1):\n                timestamp = event.get('timestamp', 0)\n                mins, secs = divmod(timestamp, 60)\n                event_type = event.get('event_type', '')\n                outcome = event.get('outcome', '')\n                description = event.get('description', '')[:50] + \"...\"\n                \n                # Update counters (no rebounds)\n                if event_type == '2pt_shot' and outcome == 'made':\n                    pt2 += 1\n                elif event_type == '3pt_shot' and outcome == 'made':\n                    pt3 += 1\n                elif event_type == 'assist':\n                    ast += 1\n                elif event_type == 'block':\n                    blk += 1\n                elif event_type == 'steal':\n                    stl += 1\n                    \n                print(f\"   {int(mins):02d}:{int(secs):02d} - {event_type.upper()}\")\n                print(f\"        Counter: 2pt:{pt2} 3pt:{pt3} ast:{ast} blk:{blk} stl:{stl}\")\n                print(f\"        Caption: {description}\")\n                print()\n                \n            if len(display_events) > 10:\n                print(f\"   ... and {len(display_events) - 10} more events\")\n        \n        print(f\"\\\\nüìÅ Generated Files:\")\n        print(f\"   üìÑ Clean JSON (no rebounds): {json_filepath if json_filepath else 'Failed'}\")\n        print(f\"   üé• Timeline Overlay Video: {VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')}\")\n        print(f\"\\\\nüéØ Features Implemented:\")\n        print(f\"   ‚úÖ Real-time event counters (top-left vertical)\")\n        print(f\"   ‚úÖ Dense event captions (middle-bottom)\")\n        print(f\"   ‚úÖ Removed rebounds from tracking\")\n        print(f\"   ‚úÖ JSON-based data source\")\n        print(f\"   ‚úÖ Time-synced overlay updates\")\n        print(f\"   ‚úÖ Fixed filename consistency\")\n        \n    except json.JSONDecodeError as e:\n        print(f\"üö® JSON parsing error: {str(e)}\")\n    except Exception as general_error:\n        print(f\"üö® Error: {str(general_error)}\")\n\n    # Cleanup uploaded file\n    try:\n        if 'video_file' in locals():\n            genai.delete_file(video_file.name)\n            print(f\"\\\\nüßπ Cleaned up {video_file.name}\")\n    except:\n        pass"
  },
  {
   "cell_type": "markdown",
   "id": "v9984jhizb",
   "metadata": {},
   "source": [
    "## Step 5: Generate Annotated Video with Event Overlays\n",
    "\n",
    "Create an annotated version of the original video with:\n",
    "- **Real-time event counters** (top-left): Red Team vs Green Team event counts\n",
    "- **Event captions** (middle-bottom): Live descriptions of basketball events as they occur\n",
    "- **JSON results** automatically saved to `results/` folder\n",
    "\n",
    "**Output**: \n",
    "- Original video with overlays: `{original_name}_annotated.mp4`\n",
    "- Analysis JSON file: `results/basketball_analysis_{video_name}_{timestamp}.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249b107-6023-4000-b02c-548cadd2315f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586d904-d75f-4778-961a-bcbb1e1445e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}