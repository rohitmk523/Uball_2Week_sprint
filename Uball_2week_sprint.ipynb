{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "sia3n835q7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Installing required dependencies...\n",
      "==================================================\n",
      "üì¶ Installing google-generativeai: Google AI SDK for Gemini models\n",
      "Requirement already satisfied: google-generativeai in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.179.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "‚úÖ google-generativeai installed successfully\n",
      "üì¶ Installing ffmpeg-python: Python wrapper for FFmpeg video processing\n",
      "Requirement already satisfied: ffmpeg-python in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (from ffmpeg-python) (1.0.0)\n",
      "‚úÖ ffmpeg-python installed successfully\n",
      "üì¶ Installing pillow: Image processing for overlay generation\n",
      "Requirement already satisfied: pillow in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (11.3.0)\n",
      "‚úÖ pillow installed successfully\n",
      "üì¶ Installing numpy: Numerical operations for video processing\n",
      "Requirement already satisfied: numpy in /Users/rohitkale/miniconda3/envs/Uball/lib/python3.11/site-packages (2.3.2)\n",
      "‚úÖ numpy installed successfully\n",
      "\n",
      "üéâ All dependencies installation complete!\n",
      "\n",
      "üìã Required system dependencies:\n",
      "   - FFmpeg (install via: brew install ffmpeg on macOS, apt install ffmpeg on Ubuntu)\n",
      "   - Make sure FFmpeg is available in your system PATH\n"
     ]
    }
   ],
   "source": [
    "# Required dependencies for basketball video analysis and overlay generation\n",
    "DEPENDENCIES = {\n",
    "    \"google-generativeai\": \"Google AI SDK for Gemini models\",\n",
    "    \"ffmpeg-python\": \"Python wrapper for FFmpeg video processing\", \n",
    "    \"pillow\": \"Image processing for overlay generation\",\n",
    "    \"numpy\": \"Numerical operations for video processing\"\n",
    "}\n",
    "\n",
    "print(\"üîß Installing required dependencies...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package_name, description):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        print(f\"üì¶ Installing {package_name}: {description}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"‚úÖ {package_name} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to install {package_name}: {e}\")\n",
    "\n",
    "# Install all dependencies\n",
    "for package, description in DEPENDENCIES.items():\n",
    "    install_package(package, description)\n",
    "\n",
    "print(\"\\nüéâ All dependencies installation complete!\")\n",
    "print(\"\\nüìã Required system dependencies:\")\n",
    "print(\"   - FFmpeg (install via: brew install ffmpeg on macOS, apt install ffmpeg on Ubuntu)\")\n",
    "print(\"   - Make sure FFmpeg is available in your system PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conwbmmb6qf",
   "metadata": {},
   "source": [
    "# üèÄ Basketball Video Analysis using Gemini 2.5 Pro\n",
    "\n",
    "This notebook analyzes basketball game videos to automatically detect and track key events including:\n",
    "- **2-Point Shots** (Made/Miss)\n",
    "- **3-Point Shots** (Made/Miss) \n",
    "- **Assists**\n",
    "- **Steals**\n",
    "- **Blocks**\n",
    "\n",
    "## üìã Analysis Workflow\n",
    "\n",
    "1. **Setup**: Install dependencies and configure Google AI API\n",
    "2. **Upload**: Upload video file to Google AI platform\n",
    "3. **Process**: Wait for video processing to complete\n",
    "4. **Analyze**: Send video to Gemini 2.5 Pro for basketball event detection\n",
    "5. **Results**: Extract and display structured JSON timeline of events\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Install Dependencies\n",
    "\n",
    "First, we'll install the Google AI Python SDK for accessing Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4b274666-7e8e-429f-b7c9-3b3c975118bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Please enter your Google API key:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "API Key:  AIzaSyBAsS7OV2daJAhf0YxcBtZBwGGPpid_iuc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for video analysis\n",
    "import google.generativeai as genai  # Google AI SDK for Gemini models\n",
    "import time                          # For handling processing delays\n",
    "import json                          # For JSON parsing and formatting\n",
    "import os                            # For environment variable access\n",
    "\n",
    "# Configure API authentication for Google AI services\n",
    "# For Jupyter notebook, we support both environment variables and manual input\n",
    "try:\n",
    "    # First, try to get API key from environment variable\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    \n",
    "    # If not found, prompt user to enter it manually\n",
    "    if not GOOGLE_API_KEY:\n",
    "        print(\"üîë Please enter your Google API key:\")\n",
    "        GOOGLE_API_KEY = input(\"API Key: \")\n",
    "    \n",
    "    # Configure the Google AI SDK with the API key\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    print(\"‚úÖ API Key configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"üö® Could not configure Google API Key.\")\n",
    "    print(\"Please set the GOOGLE_API_KEY environment variable or enter it manually.\")\n",
    "    print(\"You can get your API key from: https://aistudio.google.com/app/apikey\")\n",
    "\n",
    "# --- VIDEO FILE CONFIGURATION ---\n",
    "# IMPORTANT: Update this path to match your actual video file name\n",
    "VIDEO_FILE_PATH = \"sample120s_video-1.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75anu4vd3nb",
   "metadata": {},
   "source": [
    "## Step 2: Configure API Access\n",
    "\n",
    "Set up authentication for Google AI services. You can either:\n",
    "- Set the `GOOGLE_API_KEY` environment variable, or  \n",
    "- Enter your API key manually when prompted\n",
    "\n",
    "Get your API key from: https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65b99f-4853-4157-92dd-880ac9297421",
   "metadata": {},
   "outputs": [],
   "source": "# Step 2.5: Add Timestamp Overlay Before Analysis\nif 'GOOGLE_API_KEY' not in locals() or not GOOGLE_API_KEY:\n    print(\"üö® Please run the previous cell to configure your API key first!\")\nelse:\n    import ffmpeg\n    import os\n    \n    # Check if the video file exists\n    if not os.path.exists(VIDEO_FILE_PATH):\n        print(f\"üö® Error: Video file '{VIDEO_FILE_PATH}' not found!\")\n        print(\"Please make sure the video file is in the same directory as this notebook.\")\n    else:\n        try:\n            # Create timestamped version of the video\n            timestamped_video_path = VIDEO_FILE_PATH.replace('.mp4', '_with_timestamps.mp4')\n            \n            print(f\"üìπ Adding timestamp overlay to: {VIDEO_FILE_PATH}\")\n            print(f\"üïê Creating timestamped version: {timestamped_video_path}\")\n            \n            # Get video info\n            probe = ffmpeg.probe(VIDEO_FILE_PATH)\n            duration = float(probe['format']['duration'])\n            print(f\"   Duration: {duration:.2f} seconds ({duration/60:.1f} minutes)\")\n            \n            # FIXED: Use simpler timestamp format that actually works\n            input_stream = ffmpeg.input(VIDEO_FILE_PATH)\n            \n            # Create timestamp overlay with corrected format\n            # This shows elapsed time from start of video in MM:SS format\n            timestamped_stream = input_stream.filter(\n                'drawtext',\n                text='%{eif\\\\:t/60\\\\:d\\\\:2}\\\\:%{eif\\\\:mod(t,60)\\\\:d\\\\:2}',  # MM:SS format\n                x='w-text_w-30',  # 30 pixels from right edge\n                y='30',           # 30 pixels from top\n                fontsize=36,\n                fontcolor='white',\n                box=1,\n                boxcolor='black@0.9',\n                boxborderw=6\n            )\n            \n            # Create output with timestamp overlay\n            output = ffmpeg.output(timestamped_stream, timestamped_video_path, \n                                 vcodec='libx264', acodec='copy', preset='fast', crf=18)\n            \n            # Run FFmpeg to create timestamped video\n            print(\"üîß Running FFmpeg to add timestamp overlay...\")\n            ffmpeg.run(output, overwrite_output=True, quiet=False)\n            \n            # Verify the timestamped video was created\n            if os.path.exists(timestamped_video_path):\n                file_size = os.path.getsize(timestamped_video_path)\n                print(f\"‚úÖ Timestamp overlay added successfully!\")\n                print(f\"üìÅ Timestamped video: {timestamped_video_path}\")\n                print(f\"üìä File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)\")\n                print(f\"üéØ Timestamp location: Top-right corner (MM:SS format)\")\n                print(f\"üí° Format: Shows elapsed time from video start\")\n                \n                # Test with a quick frame extraction to verify overlay\n                print(\"\\\\nüîç Testing timestamp overlay visibility...\")\n                test_frame_path = timestamped_video_path.replace('.mp4', '_test_frame.jpg')\n                (\n                    ffmpeg\n                    .input(timestamped_video_path, ss=30)  # Extract frame at 30 seconds\n                    .output(test_frame_path, vframes=1)\n                    .overwrite_output()\n                    .run(quiet=True)\n                )\n                \n                if os.path.exists(test_frame_path):\n                    print(f\"‚úÖ Test frame extracted: {test_frame_path}\")\n                    print(\"   You can check this image to verify timestamp overlay is visible\")\n                \n            else:\n                print(\"‚ùå Timestamped video creation failed\")\n                timestamped_video_path = VIDEO_FILE_PATH  # Fall back to original\n            \n            # Now upload the timestamped video\n            print(f\"\\\\nüì§ Uploading timestamped video to Google AI...\")\n            \n            # Upload the timestamped video file to Google AI platform\n            video_file = genai.upload_file(path=timestamped_video_path)\n            print(f\"Completed upload: {video_file.name}\")\n\n            # Wait for video processing to complete\n            while video_file.state.name == \"PROCESSING\":\n                print(\"‚è≥ Waiting for video processing...\")\n                time.sleep(10)\n                video_file = genai.get_file(video_file.name)\n\n            # Check if processing failed\n            if video_file.state.name == \"FAILED\":\n                raise ValueError(\"Video processing failed.\")\n\n            print(f\"‚úÖ Timestamped video processed successfully: {video_file.uri}\")\n            print(f\"üí° Benefits:\")\n            print(f\"   ‚Ä¢ Visual timestamp reference at top-right corner\")\n            print(f\"   ‚Ä¢ AI can see exact elapsed time for each event\")\n            print(f\"   ‚Ä¢ Prevents timestamp hallucinations beyond video duration\")\n            print(f\"   ‚Ä¢ Format: MM:SS (e.g., 02:15 for 2 minutes 15 seconds)\")\n            \n        except ffmpeg.Error as e:\n            print(f\"üö® FFmpeg error creating timestamp overlay:\")\n            if hasattr(e, 'stderr') and e.stderr:\n                print(f\"   Error details: {e.stderr.decode('utf-8')}\")\n            print(\"üí° Falling back to original video upload...\")\n            \n            # Fallback: upload original video\n            video_file = genai.upload_file(path=VIDEO_FILE_PATH)\n            print(f\"Completed upload: {video_file.name}\")\n            \n            while video_file.state.name == \"PROCESSING\":\n                print(\"‚è≥ Waiting for video processing...\")\n                time.sleep(10)\n                video_file = genai.get_file(video_file.name)\n                \n            if video_file.state.name == \"FAILED\":\n                raise ValueError(\"Video processing failed.\")\n                \n            print(f\"‚úÖ Original video processed: {video_file.uri}\")\n            \n        except Exception as e:\n            print(f\"üö® Error: {str(e)}\")\n            print(\"üí° Falling back to original video...\")\n            # Fallback: upload original video\n            try:\n                video_file = genai.upload_file(path=VIDEO_FILE_PATH)\n                print(f\"Fallback upload completed: {video_file.name}\")\n                \n                while video_file.state.name == \"PROCESSING\":\n                    print(\"‚è≥ Waiting for video processing...\")\n                    time.sleep(10)\n                    video_file = genai.get_file(video_file.name)\n                    \n                print(f\"‚úÖ Fallback video processed: {video_file.uri}\")\n            except Exception as fallback_error:\n                print(f\"üö® Fallback also failed: {fallback_error}\")"
  },
  {
   "cell_type": "markdown",
   "id": "fio7sh93q0j",
   "metadata": {},
   "source": [
    "## Step 3: Video Preprocessing with Timestamp Overlay\n",
    "\n",
    "**NEW FEATURE**: Before analysis, we now add a timestamp overlay to help validate AI predictions and prevent hallucinations.\n",
    "\n",
    "### üïê **Timestamp Overlay Features:**\n",
    "- **Location**: Top-right corner of video\n",
    "- **Format**: MM:SS.s (e.g., \"02:15.3\" for 2 minutes 15.3 seconds)\n",
    "- **Style**: White text with black background box for visibility\n",
    "- **Purpose**: Visual reference to catch AI timestamp hallucinations\n",
    "\n",
    "### üìã **Process:**\n",
    "1. **Add Timestamp Overlay**: Uses FFmpeg to embed real-time timestamps\n",
    "2. **Upload Timestamped Video**: Sends the enhanced video to Google AI\n",
    "3. **Visual Validation**: AI can see exact timestamps, reducing hallucinations\n",
    "\n",
    "### üí° **Benefits:**\n",
    "- ‚úÖ **Prevents hallucinations** like the 145.8s timestamp in a 120s video\n",
    "- ‚úÖ **Visual validation** of AI timestamp predictions  \n",
    "- ‚úÖ **Easy verification** when reviewing results\n",
    "- ‚úÖ **Improved accuracy** in event timing\n",
    "\n",
    "**Important**: The system creates a `{video_name}_with_timestamps.mp4` file for processing, while keeping your original video intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cd29c55d-8648-4a09-a485-cd1f3efc87e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Sending timestamped video to Gemini 2.5 Pro...\n",
      "üïê AI will use visible timestamp overlay for accurate timing\n",
      "‚úÖ Analysis complete with timestamp validation!\n"
     ]
    }
   ],
   "source": [
    "# Validate that video upload was successful before proceeding with analysis\n",
    "if 'video_file' not in locals():\n",
    "    print(\"üö® Please run the previous cell to upload and process your video first!\")\n",
    "else:\n",
    "    try:\n",
    "        # Initialize Gemini 2.5 Pro model for advanced video analysis\n",
    "        model = genai.GenerativeModel(model_name=\"models/gemini-2.5-pro\")\n",
    "\n",
    "        # Enhanced prompt with timestamp overlay reference\n",
    "        prompt = \"\"\"\n",
    "        You are an expert basketball analyst AI specializing in comprehensive game event detection and statistics.\n",
    "        \n",
    "        IMPORTANT: This video has a timestamp overlay in the TOP-RIGHT CORNER showing the exact time (MM:SS.s format).\n",
    "        Use this visual timestamp reference to ensure accurate event timing and prevent timestamp hallucinations.\n",
    "        \n",
    "        Analyze the provided basketball video and create a detailed analysis report with the following events:\n",
    "        - 2-Point Shots (made/miss)\n",
    "        - 3-Point Shots (made/miss)\n",
    "        - Assists\n",
    "        - Steals  \n",
    "        - Blocks\n",
    "        - Rebounds (if visible)\n",
    "\n",
    "        CRITICAL: \n",
    "        1. Look at the timestamp overlay in the top-right corner for exact timing\n",
    "        2. Do NOT guess or estimate timestamps - use the visible overlay\n",
    "        3. All timestamps must match what you see in the timestamp overlay\n",
    "        4. If you can't clearly see the timestamp overlay at an event, provide your best estimate but note uncertainty\n",
    "\n",
    "        IMPORTANT: Return ONLY a valid JSON object with no additional text or markdown formatting.\n",
    "\n",
    "        Required JSON Structure:\n",
    "        {\n",
    "          \"video_info\": {\n",
    "            \"duration\": <video_duration_seconds>,\n",
    "            \"filename\": \"REPLACE_WITH_ACTUAL_FILENAME\"\n",
    "          },\n",
    "          \"processing_summary\": {\n",
    "            \"total_events_detected\": <total_count>,\n",
    "            \"processing_timestamp\": \"<current_timestamp>\",\n",
    "            \"event_types_found\": [<list_of_event_types_found>]\n",
    "          },\n",
    "          \"game_statistics\": {\n",
    "            \"total_2pt_attempts\": <count>,\n",
    "            \"total_2pt_made\": <count>,\n",
    "            \"total_3pt_attempts\": <count>, \n",
    "            \"total_3pt_made\": <count>,\n",
    "            \"total_assists\": <count>,\n",
    "            \"total_steals\": <count>,\n",
    "            \"total_blocks\": <count>\n",
    "          },\n",
    "          \"shooting_analysis\": {\n",
    "            \"2pt_shooting\": {\n",
    "              \"percentage\": <percentage>,\n",
    "              \"made\": <count>,\n",
    "              \"attempts\": <count>\n",
    "            },\n",
    "            \"3pt_shooting\": {\n",
    "              \"percentage\": <percentage>,\n",
    "              \"made\": <count>,\n",
    "              \"attempts\": <count>\n",
    "            },\n",
    "            \"overall_fg_percentage\": <percentage>\n",
    "          },\n",
    "          \"defensive_stats\": {\n",
    "            \"steals\": <count>,\n",
    "            \"blocks\": <count>,\n",
    "            \"total_defensive_actions\": <count>\n",
    "          },\n",
    "          \"playmaking\": {\n",
    "            \"assists\": <count>\n",
    "          },\n",
    "          \"detailed_events\": [\n",
    "            {\n",
    "              \"event_type\": \"2pt_shot\" | \"3pt_shot\" | \"assist\" | \"steal\" | \"block\" | \"rebound\",\n",
    "              \"timestamp\": <time_in_seconds_from_timestamp_overlay>,\n",
    "              \"description\": \"<detailed_description>\",\n",
    "              \"outcome\": \"made\" | \"miss\" | null,\n",
    "              \"location\": \"<court_location>\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "\n",
    "        Critical Requirements:\n",
    "        1. outcome: Use \"made\" or \"miss\" for 2pt_shot and 3pt_shot events, null for all other events\n",
    "        2. Do NOT include: duration, confidence, segment_id fields in detailed_events\n",
    "        3. timestamp: Read from the TOP-RIGHT timestamp overlay (convert MM:SS.s to total seconds)\n",
    "        4. Calculate accurate percentages and statistics\n",
    "        5. Include detailed descriptions of each event\n",
    "        6. Identify court locations where events occurred\n",
    "        7. REFERENCE THE TIMESTAMP OVERLAY: Use the visible time display for accurate timing\n",
    "\n",
    "        Example timestamp conversions from overlay:\n",
    "        - \"01:30.5\" ‚Üí 90.5 seconds\n",
    "        - \"02:15.2\" ‚Üí 135.2 seconds\n",
    "        - \"00:45.8\" ‚Üí 45.8 seconds\n",
    "\n",
    "        Return only the JSON object.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"\\nü§ñ Sending timestamped video to Gemini 2.5 Pro...\")\n",
    "        print(\"üïê AI will use visible timestamp overlay for accurate timing\")\n",
    "\n",
    "        # Send video and prompt to Gemini for analysis\n",
    "        response = model.generate_content([prompt, video_file],\n",
    "                                          request_options={\"timeout\": 600})\n",
    "\n",
    "        print(f\"‚úÖ Analysis complete with timestamp validation!\")\n",
    "        \n",
    "        # Store response for the next cell to process\n",
    "        analysis_response = response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üö® Error during analysis: {str(e)}\")\n",
    "        \n",
    "        # Provide specific guidance based on error type\n",
    "        if \"403\" in str(e) or \"permission\" in str(e).lower():\n",
    "            print(\"üí° This error usually means:\")\n",
    "            print(\"   - The file upload session expired\")\n",
    "            print(\"   - The file was deleted too early\")\n",
    "            print(\"   - There's an API quota or permission issue\")\n",
    "            print(\"\\nüîÑ Solution: Re-run the upload cell, then immediately run this analysis cell\")\n",
    "        elif \"quota\" in str(e).lower() or \"rate\" in str(e).lower():\n",
    "            print(\"üí° This looks like a quota/rate limiting error\")\n",
    "            print(\"   - Wait a few minutes before trying again\")\n",
    "            print(\"   - Check your API usage limits\")\n",
    "        else:\n",
    "            print(\"üí° Try:\")\n",
    "            print(\"   1. Re-run the upload cell\")\n",
    "            print(\"   2. Immediately run this cell\")\n",
    "            print(\"   3. Check your API key permissions\")\n",
    "\n",
    "# Note: File cleanup is handled in the final results cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m56b5j3umga",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Timestamped Video with Gemini 2.5 Pro\n",
    "\n",
    "Send the timestamped video to Gemini 2.5 Pro for basketball event analysis. The AI will use the visible timestamp overlay for accurate event timing.\n",
    "\n",
    "### üîç **Enhanced Analysis Features:**\n",
    "- **Timestamp Validation**: AI reads from visible top-right timestamp overlay\n",
    "- **Hallucination Prevention**: Visual reference prevents impossible timestamps\n",
    "- **Accurate Timing**: Converts MM:SS.s format to precise seconds\n",
    "- **Event Detection**: 2pt/3pt shots, assists, steals, blocks, rebounds\n",
    "\n",
    "### üí° **How It Works:**\n",
    "1. AI analyzes video with embedded timestamp overlay\n",
    "2. Uses visible time display for each event timing\n",
    "3. Converts overlay format (e.g., \"02:15.3\") to seconds (135.3)\n",
    "4. Returns structured JSON with validated timestamps\n",
    "\n",
    "This prevents issues like the previous 145.8s timestamp in a 120s video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc7dc6ac-d4bf-4293-9cfb-f7c2dd88fe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üèÄ ENHANCED BASKETBALL VIDEO OVERLAY GENERATION\n",
      "============================================================\n",
      "‚úÖ Removed 'rebound' from event_types_found\n",
      "‚úÖ Filtered out 4 rebound events\n",
      "üíæ Cleaned analysis JSON saved: results/basketball_analysis_sample120s_video-1_20250816_030033.json\n",
      "   File size: 4246 bytes\n",
      "\\nüìä Processing 15 events (rebounds removed) for enhanced timeline overlay...\n",
      "üìπ Video info: 120.1s @ 30.0fps, Audio: True\n",
      "\\nüé¨ Generating enhanced timeline overlay video...\n",
      "   üéØ Top-left: Real-time vertical stats counter\n",
      "   üì∫ Middle-bottom: Dense event captions\n",
      "   üö´ Rebounds excluded from tracking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.0.13.3)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'sample120s_video-1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    creation_time   : 2025-08-11T10:23:01.000000Z\n",
      "  Duration: 00:02:00.05, start: 0.000000, bitrate: 20210 kb/s\n",
      "  Stream #0:0[0x1](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 129 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-08-11T10:23:01.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080, 20043 kb/s, SAR 1:1 DAR 16:9, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-08-11T10:23:01.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 (h264) -> drawtext:default\n",
      "  drawtext:default -> Stream #0:0 (libx264)\n",
      "  Stream #0:0 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x13870e290] using SAR=1/1\n",
      "[libx264 @ 0x13870e290] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x13870e290] profile High, level 4.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x13870e290] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=2 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=6 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=30 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'sample120s_video-1_timeline_overlay.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 29.97 fps, 30k tbn\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 129 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-08-11T10:23:01.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "[out#0/mp4 @ 0x13871dfc0] video:133391KiB audio:1901KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.083471%\n",
      "frame= 3598 fps= 73 q=-1.0 Lsize=  135406KiB time=00:01:59.98 bitrate=9244.7kbits/s speed=2.42x    \n",
      "[libx264 @ 0x13870e290] frame I:15    Avg QP:14.83  size:442576\n",
      "[libx264 @ 0x13870e290] frame P:2815  Avg QP:17.52  size: 43379\n",
      "[libx264 @ 0x13870e290] frame B:768   Avg QP:22.53  size: 10212\n",
      "[libx264 @ 0x13870e290] consecutive B-frames: 68.1%  8.3%  5.5% 18.0%\n",
      "[libx264 @ 0x13870e290] mb I  I16..4:  3.7% 22.5% 73.8%\n",
      "[libx264 @ 0x13870e290] mb P  I16..4:  0.2%  0.8%  1.4%  P16..4: 38.5%  8.4%  8.5%  0.0%  0.0%    skip:42.1%\n",
      "[libx264 @ 0x13870e290] mb B  I16..4:  0.2%  0.5%  0.8%  B16..8:  8.0%  4.2%  1.3%  direct: 3.8%  skip:81.2%  L0:34.4% L1:48.5% BI:17.1%\n",
      "[libx264 @ 0x13870e290] 8x8 transform intra:32.0% inter:46.1%\n",
      "[libx264 @ 0x13870e290] coded y,uvDC,uvAC intra: 76.8% 65.0% 31.5% inter: 22.9% 12.6% 1.5%\n",
      "[libx264 @ 0x13870e290] i16 v,h,dc,p: 27% 27% 26% 21%\n",
      "[libx264 @ 0x13870e290] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 20% 25%  6%  8%  5%  8%  5%  8%\n",
      "[libx264 @ 0x13870e290] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 19% 22%  5% 10%  7%  8%  5%  5%\n",
      "[libx264 @ 0x13870e290] i8c dc,h,v,p: 47% 25% 22%  6%\n",
      "[libx264 @ 0x13870e290] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x13870e290] ref P L0: 88.8% 11.2%\n",
      "[libx264 @ 0x13870e290] ref B L0: 91.2%  8.8%\n",
      "[libx264 @ 0x13870e290] ref B L1: 97.1%  2.9%\n",
      "[libx264 @ 0x13870e290] kb/s:9102.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced timeline overlay video created!\n",
      "   üìÅ File: sample120s_video-1_timeline_overlay.mp4\n",
      "   üìä Size: 138,655,401 bytes (132.2 MB)\n",
      "\\nüìà Final Game Stats (No Rebounds):\n",
      "   üèÄ 2PT Made: 2\n",
      "   üéØ 3PT Made: 1\n",
      "   ü§ù Assists: 2\n",
      "   üõ°Ô∏è  Blocks: 0\n",
      "   üí´ Steals: 1\n",
      "\\n============================================================\n",
      "üìà REAL-TIME TIMELINE PREVIEW (NO REBOUNDS)\n",
      "============================================================\n",
      "üìã Timeline overlay progression (15 events, rebounds excluded):\n",
      "   00:01 - 2PT_SHOT\n",
      "        Counter: 2pt:0 3pt:0 ast:0 blk:0 stl:0\n",
      "        Caption: Player in red #7 receives a pass in the paint and ...\n",
      "\n",
      "   00:02 - STEAL\n",
      "        Counter: 2pt:0 3pt:0 ast:0 blk:0 stl:1\n",
      "        Caption: Player in red #0 intercepts a pass near the half-c...\n",
      "\n",
      "   00:03 - 3PT_SHOT\n",
      "        Counter: 2pt:0 3pt:0 ast:0 blk:0 stl:1\n",
      "        Caption: Player in red (no number) misses a 3-point attempt...\n",
      "\n",
      "   00:21 - ASSIST\n",
      "        Counter: 2pt:0 3pt:0 ast:1 blk:0 stl:1\n",
      "        Caption: Player in green (no number) passes to a teammate u...\n",
      "\n",
      "   00:21 - 2PT_SHOT\n",
      "        Counter: 2pt:1 3pt:0 ast:1 blk:0 stl:1\n",
      "        Caption: Player in green #50 makes a layup after receiving ...\n",
      "\n",
      "   00:39 - 3PT_SHOT\n",
      "        Counter: 2pt:1 3pt:0 ast:1 blk:0 stl:1\n",
      "        Caption: Player in red (no number) misses a 3-point shot fr...\n",
      "\n",
      "   01:11 - 2PT_SHOT\n",
      "        Counter: 2pt:1 3pt:0 ast:1 blk:0 stl:1\n",
      "        Caption: Player in green (no number) misses a contested jum...\n",
      "\n",
      "   01:14 - 3PT_SHOT\n",
      "        Counter: 2pt:1 3pt:0 ast:1 blk:0 stl:1\n",
      "        Caption: Player in red #4 attempts a 3-point shot from the ...\n",
      "\n",
      "   01:21 - 2PT_SHOT\n",
      "        Counter: 2pt:1 3pt:0 ast:1 blk:0 stl:1\n",
      "        Caption: Player in red #0 misses a driving layup....\n",
      "\n",
      "   01:40 - 2PT_SHOT\n",
      "        Counter: 2pt:1 3pt:0 ast:1 blk:0 stl:1\n",
      "        Caption: Player in green (no number) misses a long 2-point ...\n",
      "\n",
      "   ... and 5 more events\n",
      "\\nüìÅ Generated Files:\n",
      "   üìÑ Clean JSON (no rebounds): results/basketball_analysis_sample120s_video-1_20250816_030033.json\n",
      "   üé• Timeline Overlay Video: sample120s_video-1_timeline_overlay.mp4\n",
      "\\nüéØ Features Implemented:\n",
      "   ‚úÖ Real-time event counters (top-left vertical)\n",
      "   ‚úÖ Dense event captions (middle-bottom)\n",
      "   ‚úÖ Removed rebounds from tracking\n",
      "   ‚úÖ JSON-based data source\n",
      "   ‚úÖ Time-synced overlay updates\n",
      "   ‚úÖ Fixed filename consistency\n",
      "\\nüßπ Cleaned up files/fqv7yx4ozezi\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Step 5: Generate Real-Time Timeline Overlay Video with JSON Event Data\n",
    "if 'analysis_response' not in locals() and 'response' not in locals():\n",
    "    print(\"üö® Please run the previous cell to get the analysis response first!\")\n",
    "else:\n",
    "    import re\n",
    "    import subprocess\n",
    "    from datetime import datetime\n",
    "    import ffmpeg\n",
    "    \n",
    "    # Use the most recent response variable available\n",
    "    current_response = analysis_response if 'analysis_response' in locals() else response\n",
    "    \n",
    "    try:\n",
    "        # Extract JSON from the AI response\n",
    "        response_text = current_response.text\n",
    "        json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            json_content = json_match.group(1).strip()\n",
    "        else:\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_content = response_text[json_start:json_end]\n",
    "            else:\n",
    "                json_content = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                first_brace = json_content.find('{')\n",
    "                if first_brace > 0:\n",
    "                    json_content = json_content[first_brace:]\n",
    "        \n",
    "        data = json.loads(json_content)\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"üèÄ ENHANCED BASKETBALL VIDEO OVERLAY GENERATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # --- REMOVE REBOUNDS FROM JSON ---\n",
    "        # Clean event_types_found\n",
    "        if 'processing_summary' in data and 'event_types_found' in data['processing_summary']:\n",
    "            event_types = data['processing_summary']['event_types_found']\n",
    "            if 'rebound' in event_types:\n",
    "                event_types.remove('rebound')\n",
    "                print(\"‚úÖ Removed 'rebound' from event_types_found\")\n",
    "        \n",
    "        # Filter out rebound events from detailed_events\n",
    "        if 'detailed_events' in data:\n",
    "            original_count = len(data['detailed_events'])\n",
    "            data['detailed_events'] = [\n",
    "                event for event in data['detailed_events'] \n",
    "                if event.get('event_type') != 'rebound'\n",
    "            ]\n",
    "            new_count = len(data['detailed_events'])\n",
    "            if original_count != new_count:\n",
    "                print(f\"‚úÖ Filtered out {original_count - new_count} rebound events\")\n",
    "        \n",
    "        # --- SAVE CLEANED JSON TO RESULTS FOLDER ---\n",
    "        try:\n",
    "            results_dir = \"results\"\n",
    "            os.makedirs(results_dir, exist_ok=True)\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            \n",
    "            # FIX: Use actual video filename from VIDEO_FILE_PATH\n",
    "            video_name_clean = VIDEO_FILE_PATH.replace('.mp4', '').replace('.', '_')\n",
    "            json_filename = f\"basketball_analysis_{video_name_clean}_{timestamp}.json\"\n",
    "            json_filepath = os.path.join(results_dir, json_filename)\n",
    "            \n",
    "            # Update video_info in JSON to match actual file\n",
    "            data['video_info']['filename'] = VIDEO_FILE_PATH\n",
    "            \n",
    "            with open(json_filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"üíæ Cleaned analysis JSON saved: {json_filepath}\")\n",
    "            print(f\"   File size: {os.path.getsize(json_filepath)} bytes\")\n",
    "            \n",
    "        except Exception as save_error:\n",
    "            print(f\"‚ö†Ô∏è  Could not save JSON file: {save_error}\")\n",
    "            json_filepath = None\n",
    "        \n",
    "        # --- ENHANCED REAL-TIME OVERLAY GENERATION ---\n",
    "        if 'detailed_events' in data and data['detailed_events']:\n",
    "            # Filter out rebounds again to be sure\n",
    "            events = [event for event in data['detailed_events'] if event.get('event_type') != 'rebound']\n",
    "            events = sorted(events, key=lambda x: float(x.get('timestamp', 0)))\n",
    "            \n",
    "            print(f\"\\\\nüìä Processing {len(events)} events (rebounds removed) for enhanced timeline overlay...\")\n",
    "            \n",
    "            def clean_text_for_ffmpeg(text):\n",
    "                text = text.replace(\"'\", \"`\")\n",
    "                text = text.replace(\":\", \"\\\\\\\\:\")\n",
    "                text = text.replace(\"%\", \"%%\")\n",
    "                text = text.replace(\"\\\\n\", \" \")\n",
    "                text = text.replace(\"[\", \"(\")\n",
    "                text = text.replace(\"]\", \")\")\n",
    "                return text\n",
    "            \n",
    "            try:\n",
    "                # Get video info using ffmpeg-python\n",
    "                probe = ffmpeg.probe(VIDEO_FILE_PATH)\n",
    "                duration = float(probe['format']['duration'])\n",
    "                video_stream_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
    "                original_fps = eval(video_stream_info['r_frame_rate'])\n",
    "                \n",
    "                # Check for audio\n",
    "                audio_streams = [stream for stream in probe['streams'] if stream['codec_type'] == 'audio']\n",
    "                has_audio = len(audio_streams) > 0\n",
    "                \n",
    "                print(f\"üìπ Video info: {duration:.1f}s @ {original_fps:.1f}fps, Audio: {has_audio}\")\n",
    "                \n",
    "                # Initialize video stream\n",
    "                input_stream = ffmpeg.input(VIDEO_FILE_PATH)\n",
    "                video_stream = input_stream.video\n",
    "                audio_stream = input_stream.audio if has_audio else None\n",
    "                \n",
    "                # --- 1. ADD EVENT CAPTIONS (MIDDLE-BOTTOM) ---\n",
    "                for event in events:\n",
    "                    description = event.get('description', '')\n",
    "                    if not description:\n",
    "                        continue\n",
    "                        \n",
    "                    timestamp = float(event.get('timestamp', 0))\n",
    "                    event_type = event.get('event_type', '').upper()\n",
    "                    outcome = event.get('outcome', '')\n",
    "                    \n",
    "                    # Format caption\n",
    "                    if outcome:\n",
    "                        caption = f\"{event_type} ({outcome.upper()}): {description}\"\n",
    "                    else:\n",
    "                        caption = f\"{event_type}: {description}\"\n",
    "                    \n",
    "                    # Clean and limit length\n",
    "                    caption = clean_text_for_ffmpeg(caption)\n",
    "                    if len(caption) > 100:\n",
    "                        caption = caption[:97] + \"...\"\n",
    "                    \n",
    "                    # Show for 4 seconds\n",
    "                    start_time = timestamp\n",
    "                    end_time = timestamp + 4.0\n",
    "                    \n",
    "                    # Apply caption (middle-bottom)\n",
    "                    video_stream = video_stream.filter(\n",
    "                        'drawtext',\n",
    "                        text=caption,\n",
    "                        x='(w-text_w)/2',  # Center horizontally\n",
    "                        y='h-th-60',       # 60 pixels from bottom\n",
    "                        fontsize=22,\n",
    "                        fontcolor='white',\n",
    "                        box=1,\n",
    "                        boxcolor='black@0.8',\n",
    "                        boxborderw=5,\n",
    "                        enable=f'between(t,{start_time},{end_time})'\n",
    "                    )\n",
    "                \n",
    "                # --- 2. ADD REAL-TIME STATS COUNTER (TOP-LEFT VERTICAL) ---\n",
    "                stats = {\"2pt\": 0, \"3pt\": 0, \"assists\": 0, \"blocks\": 0, \"steals\": 0}\n",
    "                \n",
    "                def apply_stats_block(stream, stats_dict, start, end):\n",
    "                    stats_lines = [\n",
    "                        f\"2pt: {stats_dict['2pt']}\",\n",
    "                        f\"3pt: {stats_dict['3pt']}\",\n",
    "                        f\"assists: {stats_dict['assists']}\",\n",
    "                        f\"blocks: {stats_dict['blocks']}\",\n",
    "                        f\"steals: {stats_dict['steals']}\"\n",
    "                    ]\n",
    "                    \n",
    "                    base_y = 20\n",
    "                    line_height = 35\n",
    "                    \n",
    "                    for i, line in enumerate(stats_lines):\n",
    "                        y_pos = base_y + (i * line_height)\n",
    "                        \n",
    "                        stream = stream.filter(\n",
    "                            'drawtext',\n",
    "                            text=line,\n",
    "                            x=20,  # 20 pixels from left\n",
    "                            y=y_pos,\n",
    "                            fontsize=24,\n",
    "                            fontcolor='yellow',\n",
    "                            box=1,\n",
    "                            boxcolor='black@0.8',\n",
    "                            boxborderw=5,\n",
    "                            enable=f'between(t,{start},{end})'\n",
    "                        )\n",
    "                    return stream\n",
    "                \n",
    "                # Apply initial stats (all zeros)\n",
    "                first_event_time = events[0].get('timestamp', duration) if events else duration\n",
    "                video_stream = apply_stats_block(video_stream, stats, 0, first_event_time)\n",
    "                \n",
    "                # Update stats at each event (excluding rebounds)\n",
    "                for i, event in enumerate(events):\n",
    "                    # Update counters based on event type and outcome\n",
    "                    event_type = event.get('event_type', '')\n",
    "                    outcome = event.get('outcome', '')\n",
    "                    \n",
    "                    if event_type == '2pt_shot' and outcome == 'made':\n",
    "                        stats[\"2pt\"] += 1\n",
    "                    elif event_type == '3pt_shot' and outcome == 'made':\n",
    "                        stats[\"3pt\"] += 1\n",
    "                    elif event_type == 'assist':\n",
    "                        stats[\"assists\"] += 1\n",
    "                    elif event_type == 'block':\n",
    "                        stats[\"blocks\"] += 1\n",
    "                    elif event_type == 'steal':\n",
    "                        stats[\"steals\"] += 1\n",
    "                    \n",
    "                    # Apply updated stats for time window\n",
    "                    start_time = float(event.get('timestamp', 0))\n",
    "                    end_time = events[i + 1].get('timestamp', duration) if i + 1 < len(events) else duration\n",
    "                    \n",
    "                    video_stream = apply_stats_block(video_stream, stats, start_time, end_time)\n",
    "                \n",
    "                # --- 3. CREATE OUTPUT VIDEO ---\n",
    "                output_video = VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')\n",
    "                \n",
    "                print(f\"\\\\nüé¨ Generating enhanced timeline overlay video...\")\n",
    "                print(f\"   üéØ Top-left: Real-time vertical stats counter\")\n",
    "                print(f\"   üì∫ Middle-bottom: Dense event captions\")\n",
    "                print(f\"   üö´ Rebounds excluded from tracking\")\n",
    "                \n",
    "                if has_audio:\n",
    "                    output = ffmpeg.output(\n",
    "                        video_stream, audio_stream, output_video,\n",
    "                        vcodec='libx264', \n",
    "                        acodec='copy', \n",
    "                        preset='fast', \n",
    "                        crf=18,\n",
    "                        r=original_fps\n",
    "                    )\n",
    "                else:\n",
    "                    output = ffmpeg.output(\n",
    "                        video_stream, output_video,\n",
    "                        vcodec='libx264', \n",
    "                        preset='fast', \n",
    "                        crf=18,\n",
    "                        r=original_fps\n",
    "                    )\n",
    "                \n",
    "                # Run FFmpeg\n",
    "                ffmpeg.run(output, overwrite_output=True, quiet=False)\n",
    "                \n",
    "                print(f\"‚úÖ Enhanced timeline overlay video created!\")\n",
    "                if os.path.exists(output_video):\n",
    "                    file_size = os.path.getsize(output_video)\n",
    "                    print(f\"   üìÅ File: {output_video}\")\n",
    "                    print(f\"   üìä Size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)\")\n",
    "                    \n",
    "                    # Final stats\n",
    "                    final_stats = stats\n",
    "                    print(f\"\\\\nüìà Final Game Stats (No Rebounds):\")\n",
    "                    print(f\"   üèÄ 2PT Made: {final_stats['2pt']}\")\n",
    "                    print(f\"   üéØ 3PT Made: {final_stats['3pt']}\")\n",
    "                    print(f\"   ü§ù Assists: {final_stats['assists']}\")\n",
    "                    print(f\"   üõ°Ô∏è  Blocks: {final_stats['blocks']}\")\n",
    "                    print(f\"   üí´ Steals: {final_stats['steals']}\")\n",
    "                \n",
    "            except ffmpeg.Error as e:\n",
    "                print(f\"‚ùå FFmpeg error: {e}\")\n",
    "                print(\"üí° Debug info:\")\n",
    "                print(f\"   stderr: {e.stderr.decode('utf-8') if e.stderr else 'No stderr'}\")\n",
    "                print(\"üí° Fallback: Copying original video...\")\n",
    "                import shutil\n",
    "                output_video = VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')\n",
    "                shutil.copy2(VIDEO_FILE_PATH, output_video)\n",
    "                print(f\"‚úÖ Original video copied as: {output_video}\")\n",
    "                \n",
    "            except Exception as video_error:\n",
    "                print(f\"üö® Video processing error: {video_error}\")\n",
    "                print(\"üí° Fallback: Copying original video...\")\n",
    "                import shutil\n",
    "                output_video = VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')\n",
    "                shutil.copy2(VIDEO_FILE_PATH, output_video)\n",
    "                print(f\"‚úÖ Original video copied as: {output_video}\")\n",
    "                \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No events found in JSON data\")\n",
    "            \n",
    "        # --- DISPLAY TIMELINE PREVIEW (NO REBOUNDS) ---\n",
    "        print(\"\\\\n\" + \"=\" * 60)\n",
    "        print(\"üìà REAL-TIME TIMELINE PREVIEW (NO REBOUNDS)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        if 'detailed_events' in data and data['detailed_events']:\n",
    "            # Filter out rebounds for display\n",
    "            display_events = [event for event in data['detailed_events'] if event.get('event_type') != 'rebound']\n",
    "            print(f\"üìã Timeline overlay progression ({len(display_events)} events, rebounds excluded):\")\n",
    "            \n",
    "            pt2 = pt3 = ast = blk = stl = 0\n",
    "            for i, event in enumerate(display_events[:10], 1):\n",
    "                timestamp = event.get('timestamp', 0)\n",
    "                mins, secs = divmod(timestamp, 60)\n",
    "                event_type = event.get('event_type', '')\n",
    "                outcome = event.get('outcome', '')\n",
    "                description = event.get('description', '')[:50] + \"...\"\n",
    "                \n",
    "                # Update counters (no rebounds)\n",
    "                if event_type == '2pt_shot' and outcome == 'made':\n",
    "                    pt2 += 1\n",
    "                elif event_type == '3pt_shot' and outcome == 'made':\n",
    "                    pt3 += 1\n",
    "                elif event_type == 'assist':\n",
    "                    ast += 1\n",
    "                elif event_type == 'block':\n",
    "                    blk += 1\n",
    "                elif event_type == 'steal':\n",
    "                    stl += 1\n",
    "                    \n",
    "                print(f\"   {int(mins):02d}:{int(secs):02d} - {event_type.upper()}\")\n",
    "                print(f\"        Counter: 2pt:{pt2} 3pt:{pt3} ast:{ast} blk:{blk} stl:{stl}\")\n",
    "                print(f\"        Caption: {description}\")\n",
    "                print()\n",
    "                \n",
    "            if len(display_events) > 10:\n",
    "                print(f\"   ... and {len(display_events) - 10} more events\")\n",
    "        \n",
    "        print(f\"\\\\nüìÅ Generated Files:\")\n",
    "        print(f\"   üìÑ Clean JSON (no rebounds): {json_filepath if json_filepath else 'Failed'}\")\n",
    "        print(f\"   üé• Timeline Overlay Video: {VIDEO_FILE_PATH.replace('.mp4', '_timeline_overlay.mp4')}\")\n",
    "        print(f\"\\\\nüéØ Features Implemented:\")\n",
    "        print(f\"   ‚úÖ Real-time event counters (top-left vertical)\")\n",
    "        print(f\"   ‚úÖ Dense event captions (middle-bottom)\")\n",
    "        print(f\"   ‚úÖ Removed rebounds from tracking\")\n",
    "        print(f\"   ‚úÖ JSON-based data source\")\n",
    "        print(f\"   ‚úÖ Time-synced overlay updates\")\n",
    "        print(f\"   ‚úÖ Fixed filename consistency\")\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"üö® JSON parsing error: {str(e)}\")\n",
    "    except Exception as general_error:\n",
    "        print(f\"üö® Error: {str(general_error)}\")\n",
    "\n",
    "    # Cleanup uploaded file\n",
    "    try:\n",
    "        if 'video_file' in locals():\n",
    "            genai.delete_file(video_file.name)\n",
    "            print(f\"\\\\nüßπ Cleaned up {video_file.name}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v9984jhizb",
   "metadata": {},
   "source": [
    "## Step 5: Generate Annotated Video with Event Overlays\n",
    "\n",
    "Create an annotated version of the original video with:\n",
    "- **Real-time event counters** (top-left): Red Team vs Green Team event counts\n",
    "- **Event captions** (middle-bottom): Live descriptions of basketball events as they occur\n",
    "- **JSON results** automatically saved to `results/` folder\n",
    "\n",
    "**Output**: \n",
    "- Original video with overlays: `{original_name}_annotated.mp4`\n",
    "- Analysis JSON file: `results/basketball_analysis_{video_name}_{timestamp}.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249b107-6023-4000-b02c-548cadd2315f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586d904-d75f-4778-961a-bcbb1e1445e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}